{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-01-11T21:13:43.293915Z",
     "start_time": "2026-01-11T21:13:41.964608Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sebastienlegros/Developer/DIVFM/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import torch\n",
    "import numpy as np\n",
    "from utils.dataImportation import import_data, import_earnings_date, merge_options_earnings, \\\n",
    "    apply_filters_to_options, generate_tte, split_in_sets, get_dataloader, get_datasets\n",
    "from utils.staticModels import SplitFeedforwardNNList, SplitDeepFactorNNList, SplitFrancois"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "path_to_database = '../data'\n",
    "STOCK = 'AAPL'\n",
    "USE_MLFLOW = True\n",
    "USE_EARNINGS = True\n",
    "\n",
    "BEGIN_TRAIN_DATE = '2010-01-01'  # '2000-01-01'\n",
    "END_TRAIN_DATE = '2011-01-01'  # '2021-01-01'\n",
    "BEGIN_TEST_DATE = '2011-06-01' # '2022-01-01'\n",
    "FEATURES_NAME = ['ttm', 'ttm_scaled_moneyness', 'time_to_earnings'] if USE_EARNINGS else ['ttm', 'ttm_scaled_moneyness']\n",
    "\n",
    "DEVICE = 'cpu'\n",
    " \n",
    "\n",
    "USE_LOG_VOL = True\n",
    "USE_ARBITRAGE_PENALTY = False\n",
    "USE_FRANCOIS_ET_AL = False\n",
    "\n",
    "ADD_LEVEL_AS_FACTOR = True\n",
    "ADD_TTM_SLOPE = False\n",
    "NUM_FACTORS = 4\n",
    "INPUT_SHAPE = 2\n",
    "INPUT_TTM = 2\n",
    "NUM_NEURONS = 64\n",
    "NUM_LAYERS = 3\n",
    "ACTIVATION_FUNCTION = torch.nn.GELU\n",
    "DROPOUT = 0.0\n",
    "OUTPUT_ACTIVATION = None\n",
    "BATCH_NORM = True\n",
    "OUT_BATCH_NORM = True\n",
    "\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "LR = 5e-4\n",
    "EPOCHS = 200\n",
    "SCHEDULER_STEP_SIZE = 50\n",
    "SCHEDULER_GAMMA = 0.1\n",
    "CLIPPING = 0.1\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-01-11T21:13:43.814558Z",
     "start_time": "2026-01-11T21:13:43.810045Z"
    }
   },
   "id": "a547071e97d0a526",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "if STOCK == 'SPX':\n",
    "    USE_EARNINGS = False"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-01-11T21:13:44.619751Z",
     "start_time": "2026-01-11T21:13:44.617108Z"
    }
   },
   "id": "5f78c4e9082f0592",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "labels_name = ['LOG_OM_IV'] if USE_LOG_VOL else ['OM_IV']\n",
    "model_output_fn = torch.exp if USE_LOG_VOL else torch.nn.Identity()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-01-11T21:13:45.001166Z",
     "start_time": "2026-01-11T21:13:44.999439Z"
    }
   },
   "id": "7b6e7090ec658ec8",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "options_data = import_data(path_to_database, STOCK)\n",
    "earning_dates = import_earnings_date(path_to_database, STOCK)\n",
    "options_data = merge_options_earnings(options_data, earning_dates)\n",
    "options_data = apply_filters_to_options(options_data)\n",
    "if USE_EARNINGS: options_data = generate_tte(options_data, earning_dates)\n",
    "\n",
    "train_data, valid_data, test_data = split_in_sets(options_data, BEGIN_TRAIN_DATE, END_TRAIN_DATE, BEGIN_TEST_DATE)\n",
    "train_dataset, valid_dataset, test_dataset = get_datasets(train_data, valid_data, test_data,\n",
    "                                                          FEATURES_NAME, labels_name, dtype=torch.float32)\n",
    "train_loader, valid_loader, test_loader = get_dataloader(train_dataset, valid_dataset, test_dataset, BATCH_SIZE)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-01-11T21:13:45.404614Z",
     "start_time": "2026-01-11T21:13:45.384367Z"
    }
   },
   "id": "f83fc8016217b9a7",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "if USE_EARNINGS:\n",
    "    input_size = [1, 2, 2]\n",
    "    factors_inputs_index = [[1], [0, 2], [0, 1]]\n",
    "else:\n",
    "    input_size = [1, 1, 2]\n",
    "    factors_inputs_index = [[1], [0], [0, 1]]\n",
    "    \n",
    "    \n",
    "split_feedforward = SplitFeedforwardNNList(input_size=input_size, output_size=[1, 1, 2],\n",
    "                                           num_neurons=NUM_NEURONS, num_layers=NUM_LAYERS, activation_fn=ACTIVATION_FUNCTION,\n",
    "                                           dropout=DROPOUT, output_activation=OUTPUT_ACTIVATION, batch_norm=BATCH_NORM)\n",
    "\n",
    "# ['ttm', 'ttm_scaled_moneyness', 'time_to_earnings']\n",
    "\n",
    "model = SplitDeepFactorNNList(splitFeedforwardNNList=split_feedforward, \n",
    "                      factors_inputs_index=factors_inputs_index,\n",
    "                      out_batch_norm=OUT_BATCH_NORM,\n",
    "                      output_activation=OUTPUT_ACTIVATION)\n",
    "if USE_FRANCOIS_ET_AL:\n",
    "    model = SplitFrancois(1, 0)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-01-11T21:13:45.971490Z",
     "start_time": "2026-01-11T21:13:45.965998Z"
    }
   },
   "id": "b37cd67d5b24ab76",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(list(model.parameters()), lr=LR)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=SCHEDULER_STEP_SIZE, gamma=SCHEDULER_GAMMA)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-01-11T21:13:47.149588Z",
     "start_time": "2026-01-11T21:13:46.569984Z"
    }
   },
   "id": "3cb64fabe25fc038",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-01-11T21:13:47.151880Z",
     "start_time": "2026-01-11T21:13:47.150439Z"
    }
   },
   "id": "22f51a8a378eb8b0",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "if USE_EARNINGS:\n",
    "    mlflow.set_experiment(f'{STOCK} Log Penalty Factor Model')\n",
    "else:\n",
    "    mlflow.set_experiment(f'{STOCK} Log Penalty Factor Model - without earnings')\n",
    "mlflow.start_run()\n",
    "run_id = mlflow.active_run().info.run_id\n",
    "\n",
    "mlflow.set_tag('arbitrage_penalty', USE_ARBITRAGE_PENALTY)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-01-11T21:13:47.504345Z",
     "start_time": "2026-01-11T21:13:47.336393Z"
    }
   },
   "id": "46300b24facd436b",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "'file:///Users/sebastienlegros/Developer/DIVFM/notebooks/mlruns/452981282717470609/0eb20054cba64168bedf9eacfb8e6d46/artifacts'"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.active_run().info.artifact_uri"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-01-11T21:13:47.904887Z",
     "start_time": "2026-01-11T21:13:47.901321Z"
    }
   },
   "id": "a9c33ad010c02b59",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "params = dict(\n",
    "    # Dataset\n",
    "    STOCK=STOCK,\n",
    "    USE_EARNINGS=USE_EARNINGS,\n",
    "    BEGIN_TRAIN_DATE=BEGIN_TRAIN_DATE,\n",
    "    END_TRAIN_DATE=END_TRAIN_DATE,\n",
    "    BEGIN_TEST_DATE=BEGIN_TEST_DATE,\n",
    "    FEATURES_NAME=FEATURES_NAME,\n",
    "\n",
    "    # Device\n",
    "    DEVICE=DEVICE,\n",
    "\n",
    "    # Model switches\n",
    "    USE_FRANCOIS_ET_AL=USE_FRANCOIS_ET_AL,\n",
    "    USE_LOG_VOL=USE_LOG_VOL,\n",
    "    USE_ARBITRAGE_PENALTY=USE_ARBITRAGE_PENALTY,\n",
    "    ADD_LEVEL_AS_FACTOR=ADD_LEVEL_AS_FACTOR,\n",
    "    ADD_TTM_SLOPE=ADD_TTM_SLOPE,\n",
    "\n",
    "    # Architecture\n",
    "    NUM_FACTORS=NUM_FACTORS,\n",
    "    INPUT_SHAPE=INPUT_SHAPE,\n",
    "    INPUT_TTM=INPUT_TTM,\n",
    "    NUM_NEURONS=NUM_NEURONS,\n",
    "    NUM_LAYERS=NUM_LAYERS,\n",
    "    ACTIVATION_FUNCTION=ACTIVATION_FUNCTION,\n",
    "    DROPOUT=DROPOUT,\n",
    "    OUTPUT_ACTIVATION=OUTPUT_ACTIVATION,\n",
    "    BATCH_NORM=BATCH_NORM,\n",
    "    OUT_BATCH_NORM=OUT_BATCH_NORM,\n",
    "\n",
    "    # Training\n",
    "    BATCH_SIZE=BATCH_SIZE,\n",
    "    LR=LR,\n",
    "    EPOCHS=EPOCHS,\n",
    "    SCHEDULER_STEP_SIZE=SCHEDULER_STEP_SIZE,\n",
    "    SCHEDULER_GAMMA=SCHEDULER_GAMMA,\n",
    "    CLIPPING=CLIPPING,\n",
    ")\n",
    "mlflow.log_params(params)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-01-11T21:13:48.837724Z",
     "start_time": "2026-01-11T21:13:48.825298Z"
    }
   },
   "id": "dd7e84a42a123f57",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 000 | train total 0.00020 | train RMSE 0.01423 | valid RMSE 0.00291\n",
      "epoch 001 | train total 0.00010 | train RMSE 0.00998 | valid RMSE 0.00303\n",
      "epoch 002 | train total 0.00008 | train RMSE 0.00886 | valid RMSE 0.00248\n",
      "epoch 003 | train total 0.00008 | train RMSE 0.00914 | valid RMSE 0.00279\n",
      "epoch 004 | train total 0.00007 | train RMSE 0.00859 | valid RMSE 0.00315\n",
      "epoch 005 | train total 0.00007 | train RMSE 0.00841 | valid RMSE 0.00238\n",
      "epoch 006 | train total 0.00007 | train RMSE 0.00853 | valid RMSE 0.00238\n",
      "epoch 007 | train total 0.00006 | train RMSE 0.00789 | valid RMSE 0.00247\n",
      "epoch 008 | train total 0.00006 | train RMSE 0.00762 | valid RMSE 0.00232\n",
      "epoch 009 | train total 0.00006 | train RMSE 0.00805 | valid RMSE 0.00337\n",
      "epoch 010 | train total 0.00007 | train RMSE 0.00864 | valid RMSE 0.00327\n",
      "epoch 011 | train total 0.00008 | train RMSE 0.00918 | valid RMSE 0.00337\n",
      "epoch 012 | train total 0.00008 | train RMSE 0.00901 | valid RMSE 0.00330\n",
      "epoch 013 | train total 0.00008 | train RMSE 0.00897 | valid RMSE 0.00332\n",
      "epoch 014 | train total 0.00007 | train RMSE 0.00822 | valid RMSE 0.00340\n",
      "epoch 015 | train total 0.00007 | train RMSE 0.00822 | valid RMSE 0.00301\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[12], line 84\u001B[0m\n\u001B[1;32m     80\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mepoch \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepoch\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m03d\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m | train total \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtrain_total\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.5f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m | \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     81\u001B[0m       \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain RMSE \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtrain_rmse\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.5f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m | valid RMSE \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mvalid_rmse\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.5f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     83\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m USE_MLFLOW:\n\u001B[0;32m---> 84\u001B[0m     \u001B[43mmlflow\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlog_metric\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mtrain_RMSE\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_rmse\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstep\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mepoch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     85\u001B[0m     mlflow\u001B[38;5;241m.\u001B[39mlog_metric(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain_total_loss\u001B[39m\u001B[38;5;124m'\u001B[39m, train_total, step\u001B[38;5;241m=\u001B[39mepoch)\n\u001B[1;32m     86\u001B[0m     mlflow\u001B[38;5;241m.\u001B[39mlog_metric(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mvalid_RMSE\u001B[39m\u001B[38;5;124m'\u001B[39m, valid_rmse, step\u001B[38;5;241m=\u001B[39mepoch)\n",
      "File \u001B[0;32m~/Developer/DIVFM/.venv/lib/python3.9/site-packages/mlflow/tracking/fluent.py:978\u001B[0m, in \u001B[0;36mlog_metric\u001B[0;34m(key, value, step, synchronous, timestamp, run_id, model_id, dataset)\u001B[0m\n\u001B[1;32m    973\u001B[0m timestamp \u001B[38;5;241m=\u001B[39m timestamp \u001B[38;5;129;01mor\u001B[39;00m get_current_time_millis()\n\u001B[1;32m    974\u001B[0m step \u001B[38;5;241m=\u001B[39m step \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m    975\u001B[0m model_ids \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m    976\u001B[0m     [model_id]\n\u001B[1;32m    977\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m model_id \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m--> 978\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m (\u001B[43m_get_model_ids_for_new_metric_if_exist\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrun_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstep\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;129;01mor\u001B[39;00m [\u001B[38;5;28;01mNone\u001B[39;00m])\n\u001B[1;32m    979\u001B[0m )\n\u001B[1;32m    980\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m model_id \u001B[38;5;129;01min\u001B[39;00m model_ids:\n\u001B[1;32m    981\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m MlflowClient()\u001B[38;5;241m.\u001B[39mlog_metric(\n\u001B[1;32m    982\u001B[0m         run_id,\n\u001B[1;32m    983\u001B[0m         key,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    990\u001B[0m         dataset_digest\u001B[38;5;241m=\u001B[39mdataset\u001B[38;5;241m.\u001B[39mdigest \u001B[38;5;28;01mif\u001B[39;00m dataset \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    991\u001B[0m     )\n",
      "File \u001B[0;32m~/Developer/DIVFM/.venv/lib/python3.9/site-packages/mlflow/tracking/fluent.py:1029\u001B[0m, in \u001B[0;36m_get_model_ids_for_new_metric_if_exist\u001B[0;34m(run_id, metric_step)\u001B[0m\n\u001B[1;32m   1027\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m_get_model_ids_for_new_metric_if_exist\u001B[39m(run_id: \u001B[38;5;28mstr\u001B[39m, metric_step: \u001B[38;5;28mstr\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mlist\u001B[39m[\u001B[38;5;28mstr\u001B[39m]:\n\u001B[1;32m   1028\u001B[0m     client \u001B[38;5;241m=\u001B[39m MlflowClient()\n\u001B[0;32m-> 1029\u001B[0m     run \u001B[38;5;241m=\u001B[39m \u001B[43mclient\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_run\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrun_id\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1030\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m run\u001B[38;5;241m.\u001B[39moutputs\u001B[38;5;241m.\u001B[39mmodel_outputs \u001B[38;5;28;01mif\u001B[39;00m run\u001B[38;5;241m.\u001B[39moutputs \u001B[38;5;28;01melse\u001B[39;00m []\n\u001B[1;32m   1031\u001B[0m     model_outputs_at_step \u001B[38;5;241m=\u001B[39m [mo \u001B[38;5;28;01mfor\u001B[39;00m mo \u001B[38;5;129;01min\u001B[39;00m outputs \u001B[38;5;28;01mif\u001B[39;00m mo\u001B[38;5;241m.\u001B[39mstep \u001B[38;5;241m==\u001B[39m metric_step]\n",
      "File \u001B[0;32m~/Developer/DIVFM/.venv/lib/python3.9/site-packages/mlflow/tracking/client.py:268\u001B[0m, in \u001B[0;36mMlflowClient.get_run\u001B[0;34m(self, run_id)\u001B[0m\n\u001B[1;32m    224\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mget_run\u001B[39m(\u001B[38;5;28mself\u001B[39m, run_id: \u001B[38;5;28mstr\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Run:\n\u001B[1;32m    225\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    226\u001B[0m \u001B[38;5;124;03m    Fetch the run from backend store. The resulting :py:class:`Run <mlflow.entities.Run>`\u001B[39;00m\n\u001B[1;32m    227\u001B[0m \u001B[38;5;124;03m    contains a collection of run metadata -- :py:class:`RunInfo <mlflow.entities.RunInfo>`,\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    266\u001B[0m \n\u001B[1;32m    267\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 268\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_tracking_client\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_run\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrun_id\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Developer/DIVFM/.venv/lib/python3.9/site-packages/mlflow/tracking/_tracking_service/client.py:98\u001B[0m, in \u001B[0;36mTrackingServiceClient.get_run\u001B[0;34m(self, run_id)\u001B[0m\n\u001B[1;32m     82\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Fetch the run from backend store. The resulting :py:class:`Run <mlflow.entities.Run>`\u001B[39;00m\n\u001B[1;32m     83\u001B[0m \u001B[38;5;124;03mcontains a collection of run metadata -- :py:class:`RunInfo <mlflow.entities.RunInfo>`,\u001B[39;00m\n\u001B[1;32m     84\u001B[0m \u001B[38;5;124;03mas well as a collection of run parameters, tags, and metrics --\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     95\u001B[0m \n\u001B[1;32m     96\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     97\u001B[0m _validate_run_id(run_id)\n\u001B[0;32m---> 98\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstore\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_run\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrun_id\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Developer/DIVFM/.venv/lib/python3.9/site-packages/mlflow/store/tracking/file_store.py:731\u001B[0m, in \u001B[0;36mFileStore.get_run\u001B[0;34m(self, run_id)\u001B[0m\n\u001B[1;32m    726\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m run_info \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    727\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m MlflowException(\n\u001B[1;32m    728\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRun \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mrun_id\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m metadata is in invalid state.\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    729\u001B[0m         databricks_pb2\u001B[38;5;241m.\u001B[39mINVALID_STATE,\n\u001B[1;32m    730\u001B[0m     )\n\u001B[0;32m--> 731\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_run_from_info\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrun_info\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Developer/DIVFM/.venv/lib/python3.9/site-packages/mlflow/store/tracking/file_store.py:736\u001B[0m, in \u001B[0;36mFileStore._get_run_from_info\u001B[0;34m(self, run_info)\u001B[0m\n\u001B[1;32m    734\u001B[0m metrics \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_all_metrics(run_info)\n\u001B[1;32m    735\u001B[0m params \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_all_params(run_info)\n\u001B[0;32m--> 736\u001B[0m tags \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_all_tags\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrun_info\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    737\u001B[0m inputs: RunInputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_all_inputs(run_info)\n\u001B[1;32m    738\u001B[0m outputs: RunOutputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_all_outputs(run_info)\n",
      "File \u001B[0;32m~/Developer/DIVFM/.venv/lib/python3.9/site-packages/mlflow/store/tracking/file_store.py:947\u001B[0m, in \u001B[0;36mFileStore._get_all_tags\u001B[0;34m(self, run_info)\u001B[0m\n\u001B[1;32m    946\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m_get_all_tags\u001B[39m(\u001B[38;5;28mself\u001B[39m, run_info):\n\u001B[0;32m--> 947\u001B[0m     parent_path, tag_files \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_run_files\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrun_info\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtag\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    948\u001B[0m     tags \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m    949\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m tag_file \u001B[38;5;129;01min\u001B[39;00m tag_files:\n",
      "File \u001B[0;32m~/Developer/DIVFM/.venv/lib/python3.9/site-packages/mlflow/store/tracking/file_store.py:777\u001B[0m, in \u001B[0;36mFileStore._get_run_files\u001B[0;34m(self, run_info, resource_type)\u001B[0m\n\u001B[1;32m    775\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    776\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mLooking for unknown resource under run.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 777\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_resource_files\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrun_dir\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msubfolder_name\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Developer/DIVFM/.venv/lib/python3.9/site-packages/mlflow/store/tracking/file_store.py:792\u001B[0m, in \u001B[0;36mFileStore._get_resource_files\u001B[0;34m(self, root_dir, subfolder_name)\u001B[0m\n\u001B[1;32m    790\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m name \u001B[38;5;129;01min\u001B[39;00m files:\n\u001B[1;32m    791\u001B[0m         abspath \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(root, name)\n\u001B[0;32m--> 792\u001B[0m         file_names\u001B[38;5;241m.\u001B[39mappend(\u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpath\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrelpath\u001B[49m\u001B[43m(\u001B[49m\u001B[43mabspath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msource_dirs\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m    793\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m sys\u001B[38;5;241m.\u001B[39mplatform \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mwin32\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m    794\u001B[0m     \u001B[38;5;66;03m# Turn metric relative path into metric name.\u001B[39;00m\n\u001B[1;32m    795\u001B[0m     \u001B[38;5;66;03m# Metrics can have '/' in the name. On windows, '/' is interpreted as a separator.\u001B[39;00m\n\u001B[1;32m    796\u001B[0m     \u001B[38;5;66;03m# When the metric is read back the path will use '\\' for separator.\u001B[39;00m\n\u001B[1;32m    797\u001B[0m     \u001B[38;5;66;03m# We need to translate the path into posix path.\u001B[39;00m\n\u001B[1;32m    798\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mmlflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfile_utils\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m relative_path_to_artifact_path\n",
      "File \u001B[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/posixpath.py:471\u001B[0m, in \u001B[0;36mrelpath\u001B[0;34m(path, start)\u001B[0m\n\u001B[1;32m    468\u001B[0m     start \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mfspath(start)\n\u001B[1;32m    470\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 471\u001B[0m     start_list \u001B[38;5;241m=\u001B[39m [x \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m \u001B[43mabspath\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstart\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39msplit(sep) \u001B[38;5;28;01mif\u001B[39;00m x]\n\u001B[1;32m    472\u001B[0m     path_list \u001B[38;5;241m=\u001B[39m [x \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m abspath(path)\u001B[38;5;241m.\u001B[39msplit(sep) \u001B[38;5;28;01mif\u001B[39;00m x]\n\u001B[1;32m    473\u001B[0m     \u001B[38;5;66;03m# Work out how much of the filepath is shared by start and path.\u001B[39;00m\n",
      "File \u001B[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/posixpath.py:381\u001B[0m, in \u001B[0;36mabspath\u001B[0;34m(path)\u001B[0m\n\u001B[1;32m    379\u001B[0m         cwd \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mgetcwd()\n\u001B[1;32m    380\u001B[0m     path \u001B[38;5;241m=\u001B[39m join(cwd, path)\n\u001B[0;32m--> 381\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mnormpath\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/posixpath.py:362\u001B[0m, in \u001B[0;36mnormpath\u001B[0;34m(path)\u001B[0m\n\u001B[1;32m    359\u001B[0m     \u001B[38;5;28;01mcontinue\u001B[39;00m\n\u001B[1;32m    360\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (comp \u001B[38;5;241m!=\u001B[39m dotdot \u001B[38;5;129;01mor\u001B[39;00m (\u001B[38;5;129;01mnot\u001B[39;00m initial_slashes \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m new_comps) \u001B[38;5;129;01mor\u001B[39;00m\n\u001B[1;32m    361\u001B[0m      (new_comps \u001B[38;5;129;01mand\u001B[39;00m new_comps[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m==\u001B[39m dotdot)):\n\u001B[0;32m--> 362\u001B[0m     \u001B[43mnew_comps\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mappend\u001B[49m(comp)\n\u001B[1;32m    363\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m new_comps:\n\u001B[1;32m    364\u001B[0m     new_comps\u001B[38;5;241m.\u001B[39mpop()\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "device = DEVICE\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "m_col = 1\n",
    "tau_col = 0\n",
    "penalty_weight = 1.\n",
    "penalty = torch.tensor(0.)\n",
    "model.to(DEVICE)\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    train_loss_sum, train_fit_sum, train_penalty_sum, n_batches = 0.0, 0.0, 0.0, 0\n",
    "    for features, labels, num_obs_per_group, _ in train_loader:\n",
    "        n_batches += 1 \n",
    "        features, labels = features.to(device), labels.to(device)\n",
    "        factors, betas, logpred = model(features, labels, num_obs_per_group)\n",
    "        fitting_loss = loss_fn(torch.exp(logpred), torch.exp(labels))\n",
    "        \n",
    "        # # penalty graph (inputs need grads here only)\n",
    "        if USE_ARBITRAGE_PENALTY:\n",
    "            x = features.detach().clone().requires_grad_(True)\n",
    "            _, _, log_IV_pred_p = model(x, labels, num_obs_per_group)\n",
    "\n",
    "\n",
    "            # compute derivatives w.r.t. M on IV_pred_p\n",
    "            n = log_IV_pred_p if log_IV_pred_p.ndim == 2 else log_IV_pred_p.unsqueeze(1)\n",
    "\n",
    "            n_M_full = torch.autograd.grad(\n",
    "                outputs=n, inputs=x, grad_outputs=torch.ones_like(n),\n",
    "                create_graph=True, retain_graph=True\n",
    "            )[0]\n",
    "            n_M = n_M_full[:, m_col:m_col + 1]\n",
    "\n",
    "            n_MM_full = torch.autograd.grad(\n",
    "                outputs=n_M, inputs=x, grad_outputs=torch.ones_like(n_M),\n",
    "                create_graph=True\n",
    "            )[0]\n",
    "            n_MM = n_MM_full[:, m_col:m_col + 1]\n",
    "\n",
    "            M = x[:, m_col:m_col + 1]\n",
    "            tau = x[:, tau_col:tau_col + 1]\n",
    "\n",
    "            expr = n_MM + n_M ** 2 + torch.exp(2 * n) * (1 - n_M * M) ** 2 \\\n",
    "                   - (tau / 4.0) * n_M ** 2 * torch.exp(2 * n)\n",
    "            penalty = torch.relu(-expr).mean()\n",
    "        \n",
    "        # total loss\n",
    "        loss = fitting_loss + penalty_weight * penalty\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        if CLIPPING is not None:\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=CLIPPING)\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss_sum += loss.detach().item()\n",
    "        train_fit_sum += fitting_loss.detach().item()\n",
    "        train_penalty_sum += penalty.detach().item()\n",
    "\n",
    "    train_total = train_loss_sum / n_batches\n",
    "    train_rmse = float(np.sqrt(train_fit_sum / n_batches))\n",
    "    train_penalty = train_penalty_sum / n_batches\n",
    "\n",
    "    if scheduler is not None:\n",
    "        scheduler.step()\n",
    "\n",
    "    # Validation (no penalty)\n",
    "    valid_rmse = None\n",
    "    if valid_loader is not None:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            v_sum, v_batches = 0.0, 0\n",
    "            for features, labels, num_obs_per_group, groups in valid_loader:\n",
    "                v_batches += 1\n",
    "                features, labels = features.to(device), labels.to(device)\n",
    "                factors, betas, logpred = model(features, labels, num_obs_per_group)\n",
    "                fitting_loss = loss_fn(torch.exp(logpred), torch.exp(labels))\n",
    "                v_sum += fitting_loss.item()\n",
    "            valid_rmse = float(np.sqrt(v_sum / v_batches))\n",
    "\n",
    "    \n",
    "    print(f\"epoch {epoch:03d} | train total {train_total:.5f} | \"\n",
    "          f\"train RMSE {train_rmse:.5f} | valid RMSE {valid_rmse:.5f}\")\n",
    "\n",
    "    if USE_MLFLOW:\n",
    "        mlflow.log_metric('train_RMSE', train_rmse, step=epoch)\n",
    "        mlflow.log_metric('train_total_loss', train_total, step=epoch)\n",
    "        mlflow.log_metric('valid_RMSE', valid_rmse, step=epoch)\n",
    "        mlflow.log_metric('train_penalty', train_penalty, step=epoch)\n",
    "\n",
    "\n",
    "    # if valid_rmse is not None and (best_val is None or valid_rmse < best_val):\n",
    "    #     best_val = valid_rmse\n",
    "    #     best_model = copy.copy(model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-01-11T21:13:52.776735Z",
     "start_time": "2026-01-11T21:13:49.785301Z"
    }
   },
   "id": "5a7ff0761a298257",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/11 16:13:53 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "\u001B[31m2026/01/11 16:13:55 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "<mlflow.models.model.ModelInfo at 0x16695e430>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.pytorch.log_model(model.to('cpu'), 'model')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-01-11T21:13:55.268129Z",
     "start_time": "2026-01-11T21:13:53.237477Z"
    }
   },
   "id": "71746e2aad4696da",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable parameters: 39364\n"
     ]
    }
   ],
   "source": [
    "def count_trainable_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "n_params = count_trainable_parameters(model)\n",
    "print(f\"Trainable parameters: {n_params}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-01-11T21:13:56.636363Z",
     "start_time": "2026-01-11T21:13:56.632042Z"
    }
   },
   "id": "906623aa39495e3",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "68594770fa2f2f9e",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
